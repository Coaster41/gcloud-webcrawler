# GCloud Webcrawler (Spider)
### By Coen Adler and Kevin Yosifov

The webcrawler is designed to parse through new news articles once every 24 hours. It will identify keywords in each of these articles (we'll call them topics). Seperately we will have a list of emails and the topics that they find interesting. Anytime an article contains a topic that matches one stored seperately it will email the url of the article to the interested party. 
